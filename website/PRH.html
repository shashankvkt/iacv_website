<!DOCTYPE HTML>

<html>
	<head>
		<title>PRH database</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="subpage">

		<!-- Header -->
			<header id="header">
				<!-- <img src="images/logo.jpg" alt="logo" /> -->
				<div class="inner">
					<nav id="nav">
						<a href="index.html"><b>Home</b></a>
                        <a href="People.html"><b>People</b></a>
						<!--<a href="research_areas.html"><b>Areas of Research</b></a>-->
						<a href="Publications.html"><b>Publications</b></a>
						<a href="Openings.html"><b>Current openings</b></a>
						
					</nav>
					<a href="#navPanel" class="navPanelToggle"><span class="fa fa-bars"></span></a>
				</div>
			</header>
		<!-- Main -->
			<section id="main" class="wrapper">
				<div class="inner">
					<header class="align-center">
						<h2><b>Heterogenous Face Recognition across Pose and Resolution Database</b></h2>
							
							   <h4><b> <a href ="https://sites.google.com/site/sivaramprasad443/"target="_blank"> Sivaram Prasad Mudunuri <ast>*</ast></a></b> <span style="display:inline-block; width: 100px;"></span> Shashanka Venkataramanan <ast>*</ast> <span style="display:inline-block; width: 100px;"></span><a href = "http://www.ee.iisc.ac.in/new/people/faculty/soma.biswas/index.html"target="_blank"> Soma Biswas </b></a></h4>
							
					</header>
					<br>
					<header class="align-center">
						<h2> <b>Abstract</b></h2>
						<br>
						<h4 style="text-align:justify;"><b>Recently, near-infrared (NIR) images are increasngly being captured for recognizing faces in low-light/night-time conditions. Matching these images against the controlled high resolution visible facial images usually present in the	database is a challenging task. In surveillance scenarios, the NIR
						images can have very low resolution and also non-frontal pose which makes the problem even more challenging. In this work, we propose an orthogonal dictionary alignment approach for addressing this problem. We also propose a re-ranking approach to further improve the recognition performance for each probe by
						combining the rank list given by the proposed algorithm with that given by another complementary feature/algorithm. Finally, we	have also collected our own database HPR (Heterogeneous face recognition across Pose and Resolution) which has facial images captured from two surveillance quality NIR cameras and one	high resolution visible camera, with significant variations in head pose and resolution, which we will make publicly available. This dataset will facilitate systematic research in this very challenging and important research area. Extensive experiments on the	modified CASIA NIR-VIS 2.0 database, Surveillance Camera face database and our HPR database shows the effectiveness of the	proposed approaches and the collected database.</b></h4>
						
					</header>
					<br>
					<header class="align-center">
						<h2> <b>Database Description</b></h2>
						<h4 class="align-left"><b>The proposed database has the following features:-</b></
						<ol class="align-left">
							<b><li style="text-align:justify;"> The database has images from 200 subjects captured with two surveillance quality cameras which can work under low light conditions in NIR mode and one HR VIS camera which captures mugshot photos.</b></li> </b>

							<b><li style="text-align:justify;"> We take the HR VIS mugshot gallery images of subjects at 4ft. distance from the camera at seven poses which accounts to a total of 1400 HR VIS images.</b></li></b>

							<b><li style="text-align:justify;"> The NIR still images are captured when the subjects stand at three different distances (8ft., 12ft. and 16ft.) from the two NIR cameras thus accounting to a total of 4200 images from each camera.</b></li></b>

							<b><li style="text-align:justify;"> The VIS images are saved as: subSubID_posePoseID.png and NIR images are saved as: camCamID_subSubID_posePoseID_distDistID.bmp. </b></li></b>
						</ol>
						</h4>
						<br>
						<img src="images/prh_imgs.png" align="center" width="650" height="550" alt="IISc Logo">	
						<p style="text-align:justify;"><b>Sample images of our proposed PRH database. First column: HR VIS faces at 7 different poses (pose 00 to pose 06); Column 2 to 4: NIR faces at same pose as that of HR VIS face of that row but captured with CP Plus PTZ Camera (NIR cam01) when the subject is standing at 8 ft., 12 ft. and 16 ft. distances
respectively. Column 5 to 7: Same as that of column 2 to 5 but captured with HIK Vision Bullet Camera (NIR cam02).</b> </p>
					</header>
					<br>

					<header class="align-center">
						<h2> <b>Downloads</b></h2>
						<br>
						<h4 class="align-left"><b>Database:</b> <span style="display:inline-block; width: 155px;"></span> <b><a href="https://drive.google.com/open?id=1Hqk90jjbhFCEPt801En53H2XAW_IOKOW"target="_blank"> Images</b></a> <span style="display:inline-block; width: 125px;"></span><b><a href="https://drive.google.com/open?id=1r_J-tGI18IbZWXUuf6BTmr6nByEQ1JE9"target="_blank"> Videos</b></a></h4>
						<br>
						<h4 class="align-left"><b>Read Me:</b> <span style="display:inline-block; width: 160px;"></span> <b><a href="https://drive.google.com/open?id=1pCF1TOTqGqsYdqLjmKB11S82hJfKuM9x"target="_blank"> ReadMe.txt</b></a> </h4>
						<br>
						<h4 class="align-left"><b>Train & Test Splits:</b> <span style="display:inline-block; width: 80px;"></span> <b><a href = "https://drive.google.com/open?id=1T1i2-wdtz_h-dl4NYuGi63FlpqMLdiyI"target="_blank"> Train_split.m</b> </a><span style="display:inline-block; width: 80px;"></span> <b><a href = "https://drive.google.com/open?id=14Ti8grpPGkP-hSi0XaFsm5LI6KzCohow"target="_blank"> Test_split.m</b> </a></h4>

					</header>

					</header>
					<br>

					<header class="align-center">
					<h2> <b>Citations</b></h2>
					</header>

					<header class="align-center">
					<h2> <b>License</b></h2>
					</header>




